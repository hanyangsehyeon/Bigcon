import streamlit as st
import asyncio
import json

from mcp.client.stdio import stdio_client
from mcp import ClientSession, StdioServerParameters
from langchain_mcp_adapters.tools import load_mcp_tools
from langgraph.prebuilt import create_react_agent
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage

from PIL import Image
from pathlib import Path

# í™˜ê²½ë³€ìˆ˜
ASSETS = Path("assets")
GOOGLE_API_KEY = st.secrets["GOOGLE_API_KEY"]

system_prompt = """
ë‹¹ì‹ ì€ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë§ˆì¼€íŒ… ì „ëµì„ ì œì•ˆí•˜ëŠ” ì „ë¬¸ ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤.
ë‹¹ì‹ ì˜ ë‹µë³€ì€ ë°˜ë“œì‹œ JSON í˜•ì‹ì´ì–´ì•¼ í•©ë‹ˆë‹¤. ë‹¤ë¥¸ ì„¤ëª… ì—†ì´ JSON ì½”ë“œë§Œ ì¶œë ¥í•´ì•¼ í•©ë‹ˆë‹¤.

JSON êµ¬ì¡°ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ê°ì²´ë“¤ì˜ ë¦¬ìŠ¤íŠ¸(ë°°ì—´) í˜•íƒœì—¬ì•¼ í•©ë‹ˆë‹¤:
[
  {
    "section": "ë§ˆì¼€íŒ… ì „ëµì˜ ì£¼ì œë‚˜ ë‹¨ê³„",
    "content": "í•´ë‹¹ ì£¼ì œì— ëŒ€í•œ êµ¬ì²´ì ì¸ ë§ˆì¼€íŒ… ì œì•ˆ ë‚´ìš©. ë§Œì•½ ë‚´ìš©ì— ë§ˆí¬ë‹¤ìš´ í…Œì´ë¸”ê³¼ ê°™ì´ ì—¬ëŸ¬ ì¤„ì´ í¬í•¨ëœë‹¤ë©´, ë°˜ë“œì‹œ ê°œí–‰ ë¬¸ìë¥¼ '\\n'ìœ¼ë¡œ ì´ìŠ¤ì¼€ì´í”„ ì²˜ë¦¬í•´ì•¼ í•©ë‹ˆë‹¤.",
    "basis": "í•´ë‹¹ ì œì•ˆì„ ë’·ë°›ì¹¨í•˜ëŠ” ë°ì´í„° ê¸°ë°˜ì˜ ê·¼ê±°"
  }
]

## ì˜ˆì‹œ ##
ë‹¤ìŒì€ contentì— ë§ˆí¬ë‹¤ìš´ í…Œì´ë¸”ì´ í¬í•¨ëœ ê²½ìš°ì˜ ì˜¬ë°”ë¥¸ JSON í˜•ì‹ì…ë‹ˆë‹¤:
[
  {
    "section": "ì£¼ìš” ê³ ê° ë¶„ì„",
    "content": "ì•„ë˜ëŠ” ì£¼ìš” ê³ ê°ì¸µì˜ ì—°ë ¹ ë° ì„±ë³„ ë¶„í¬ì…ë‹ˆë‹¤.\\n\\n| ì—°ë ¹ëŒ€ | ë‚¨ì„± | ì—¬ì„± |\\n|---|---|---|\\n| 20ëŒ€ | 15% | 25% |\\n| 30ëŒ€ | 30% | 20% |\\n| 40ëŒ€ | 5% | 5% |",
    "basis": "ê°€ë§¹ì ì˜ ìµœê·¼ 3ê°œì›” ê²°ì œ ë°ì´í„°ë¥¼ ë¶„ì„í•œ ê²°ê³¼ì…ë‹ˆë‹¤."
  }
]

ì‚¬ìš©ìê°€ ê°€ë§¹ì ëª…ì„ ì…ë ¥í•˜ë©´, ë‹¹ì‹ ì€ ì œê³µëœ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ìœ„ JSON í˜•ì‹ì— ë§ì¶° ì²´ê³„ì ì¸ ë§ˆì¼€íŒ… ì „ëµì„ ì œì•ˆí•´ì•¼ í•©ë‹ˆë‹¤.
ëª¨ë“  ì œì•ˆ(content)ì—ëŠ” ë°˜ë“œì‹œ ë°ì´í„°ì— ê¸°ë°˜í•œ ê·¼ê±°(basis)ê°€ í•¨ê»˜ ì œì‹œë˜ì–´ì•¼ í•©ë‹ˆë‹¤.
ë¶„ì„ ê²°ê³¼ëŠ” ê°€ëŠ¥í•œ í‘œ(ë§ˆí¬ë‹¤ìš´ í˜•ì‹)ë¥¼ ì‚¬ìš©í•˜ì—¬ 'content'ì— í¬í•¨ì‹œí‚¤ë©´ ê°€ë…ì„±ì„ ë†’ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
"""
greeting = """ë§ˆì¼€íŒ…ì´ í•„ìš”í•œ ê°€ë§¹ì ì„ ì•Œë ¤ì£¼ì„¸ìš” \nì£¼ì†Œë„ í•¨ê»˜ ì…ë ¥í•´ì£¼ì‹œë©´, ê°€ë§¹ì ì˜ ì •ë³´ë¥¼ íŠ¹í™”í•˜ëŠ”ë° ë„ì›€ì´ ë©ë‹ˆë‹¤."""

# Streamlit App UI
@st.cache_data 
def load_image(name: str):
    return Image.open(ASSETS / name)

st.set_page_config(page_title="2025ë…„ ë¹…ì½˜í…ŒìŠ¤íŠ¸ AIë°ì´í„° í™œìš©ë¶„ì•¼ - SAVAGE")

def clear_chat_history():
    st.session_state.messages = [SystemMessage(content=system_prompt), AIMessage(content=greeting)]

# ì‚¬ì´ë“œë°”
with st.sidebar:
    st.image(load_image("shc_ci_basic_00.png"), width='stretch')
    st.markdown("<p style='text-align: center;'>2025 Big Contest</p>", unsafe_allow_html=True)
    st.markdown("<p style='text-align: center;'>AI DATA í™œìš©ë¶„ì•¼</p>", unsafe_allow_html=True)
    st.write("")
    col1, col2, col3 = st.columns([1,2,1])  # ë¹„ìœ¨ ì¡°ì • ê°€ëŠ¥
    with col2:
        st.button('Clear Chat History', on_click=clear_chat_history)

# í—¤ë”
st.title("ì‹ í•œì¹´ë“œ ì†Œìƒê³µì¸ ğŸ”‘ ë¹„ë°€ìƒë‹´ì†Œ")
st.subheader("#ìš°ë¦¬ë™ë„¤ #ìˆ¨ì€ë§›ì§‘ #ì†Œìƒê³µì¸ #ë§ˆì¼€íŒ… #ì „ëµ .. ğŸ¤¤")
st.image(load_image("image_gen3.png"), width='stretch', caption="ğŸŒ€ ë¨¸ë¦¬ì•„í”ˆ ë§ˆì¼€íŒ… ğŸ“Š ì–´ë–»ê²Œ í•˜ë©´ ì¢‹ì„ê¹Œ?")
st.write("")

# ë©”ì‹œì§€ ìƒíƒœ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = [
        SystemMessage(content=system_prompt),
        AIMessage(content=greeting)
    ]

# ì´ˆê¸° ë©”ì‹œì§€ í™”ë©´ í‘œì‹œ
for message in st.session_state.messages:
    if isinstance(message, HumanMessage):
        with st.chat_message("user"):
            st.write(message.content)
    elif isinstance(message, AIMessage):
        with st.chat_message("assistant"):
            st.write(message.content)

def render_chat_message(role: str, content: str):
    with st.chat_message(role):
        st.markdown(content.replace("<br>", "  \n"))

# LLM ëª¨ë¸ ì„ íƒ
llm = ChatGoogleGenerativeAI(
        model="gemini-2.5-flash",  # ìµœì‹  Gemini 2.5 Flash ëª¨ë¸
        google_api_key=GOOGLE_API_KEY,
        temperature=0.1
    )

# MCP ì„œë²„ íŒŒë¼ë¯¸í„°(í™˜ê²½ì— ë§ê²Œ ëª…ë ¹ ìˆ˜ì •)
server_params = StdioServerParameters(
    command="uv",
    args=["run","mcp_server.py"],
    env=None
)

# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
async def process_user_input():
    """ì‚¬ìš©ì ì…ë ¥ì„ ì²˜ë¦¬í•˜ëŠ” async í•¨ìˆ˜"""
    async with stdio_client(server_params) as (read, write):
        # ìŠ¤íŠ¸ë¦¼ìœ¼ë¡œ ClientSessionì„ ë§Œë“¤ê³ 
        async with ClientSession(read, write) as session:
            # ì„¸ì…˜ì„ initialize í•œë‹¤
            await session.initialize()

            # MCP íˆ´ ë¡œë“œ
            tools = await load_mcp_tools(session)

            # ì—ì´ì „íŠ¸ ìƒì„±
            agent = create_react_agent(llm, tools)

            # ì—ì´ì „íŠ¸ì— ì „ì²´ ëŒ€í™” íˆìŠ¤í† ë¦¬ ì „ë‹¬
            agent_response = await agent.ainvoke({"messages": st.session_state.messages})
            
            # AI ì‘ë‹µì„ ëŒ€í™” íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
            ai_message = agent_response["messages"][-1]  # ë§ˆì§€ë§‰ ë©”ì‹œì§€ê°€ AI ì‘ë‹µ

            return ai_message.content
            

# ì‚¬ìš©ì ì…ë ¥ ì°½
if query := st.chat_input("ê°€ë§¹ì  ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš”"):
    # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
    st.session_state.messages.append(HumanMessage(content=query))
    render_chat_message("user", query)

    with st.spinner("Thinking..."):
        try:
            # ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
            reply = asyncio.run(process_user_input())
            st.session_state.messages.append(AIMessage(content=reply))
            with st.chat_message("assistant"):
                try:
                    # JSON íŒŒì‹±
                    response_data = json.loads(reply)
                    
                    # ê° ì„¹ì…˜ì„ ìˆœíšŒí•˜ë©° UIì— ë Œë”ë§
                    for item in response_data:
                        section = item.get("section", "ê²°ê³¼")
                        content = item.get("content", "")
                        basis = item.get("basis", "")

                        st.subheader(f"âœ… {section}")
                        st.markdown(content)
                        
                        if basis:
                            with st.expander("ğŸ’¡ ë°ì´í„° ê¸°ë°˜ ê·¼ê±° ë³´ê¸°"):
                                st.info(basis)
                        st.divider()

                except json.JSONDecodeError:
                    # LLMì´ ìœ íš¨í•œ JSONì„ ìƒì„±í•˜ì§€ ëª»í•œ ê²½ìš°, ì›ë³¸ í…ìŠ¤íŠ¸ë¥¼ ê·¸ëŒ€ë¡œ ë³´ì—¬ì¤Œ
                    st.error("ê²°ê³¼ë¥¼ ë¶„ì„í•˜ëŠ” ë° ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì›ë³¸ ë©”ì‹œì§€ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
                    st.markdown(reply)
        except* Exception as eg:
            # ì˜¤ë¥˜ ì²˜ë¦¬
            for i, exc in enumerate(eg.exceptions, 1):
                error_msg = f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤ #{i}: {exc!r}"
                st.session_state.messages.append(AIMessage(content=error_msg))
                render_chat_message("assistant", error_msg)
